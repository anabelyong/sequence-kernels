{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad00921-7a19-4a8f-93da-ac8a3c7e7fbd",
   "metadata": {},
   "source": [
    "### Definition: IMQ-Hamming Kernel\n",
    "Based on Amin et al.(2023), the Inverse Multiquadratic Hamming(IMQ-H) kernel is defined for sequences $x,y \\in \\mathcal{S}$, where $\\mathcal{S}$ is the space of finite strings (e.g., DNA/RNA/protein), as: \n",
    "$$\n",
    "k_{\\text{IMQ-h}}(X,Y)= \\frac{1}{1+d_{H}^{\\Phi}(X,Y))^2} = \\frac{1}{(1+|X| \\vee |Y|-(\\Phi(x)|\\Phi(Y)))^2}$$\n",
    "\n",
    "This uses: \n",
    "1) $d_H(x,y)$: a Hamming distance computed over a feature space defined by sliding window counts (k-mers).\n",
    "2) The inverse multiquadratic kernel form $k(a,b) = \\frac{C}{(\\alpha + ||\\alpha - b||^2)^{\\beta}}$, here adapted for string comparison.\n",
    "\n",
    "This paper generalizes this with parameters scale $\\alpha$ and $\\beta$, yielding: \n",
    "\n",
    "$$\n",
    "k_{\\text{IMQ-h}}(x,y)= \\frac{(1+\\alpha)^{\\beta}}{(\\alpha +d_{H}(x,y))^{\\beta}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571122d6-f88c-4dbb-93e2-d8ea9364cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaacc80-672b-4114-b1e8-6f4d22faf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mutation_with_sequences.csv')\n",
    "df = df.dropna(subset=[\"mut_seq\", \"Type\"])\n",
    "# Inputs: mutated sequences\n",
    "seqs = df[\"mut_seq\"].tolist()\n",
    "# Labels: 1 = driver, 0 = passenger\n",
    "labels = df[\"Type\"].apply(lambda x: 1.0 if x.lower() == \"driver\" else 0.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2175c8-de09-4c8a-91a4-62cfd887f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of drivers and passengers\n",
    "type_counts = df[\"Type\"].str.lower().value_counts()\n",
    "\n",
    "num_drivers = type_counts.get(\"driver\", 0)\n",
    "\n",
    "num_passengers = type_counts.get(\"passenger\", 0)\n",
    "\n",
    "print(f\"Number of driver mutations: {num_drivers}\")\n",
    "print(f\"Number of passenger mutations: {num_passengers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b220d4-0cf2-4135-9aea-6a23f6fc20a3",
   "metadata": {},
   "source": [
    "### Pick 10 Seed Points for training GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab5e24-2078-4096-a2f6-29cfee066f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"mutation_with_sequences.csv\")\n",
    "df = df.dropna(subset=[\"mut_seq\", \"Type\"])\n",
    "df = df.sample(n=200, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Sequences and labels\n",
    "seqs = df[\"mut_seq\"].tolist()\n",
    "labels = df[\"Type\"].apply(lambda x: 1.0 if x.lower() == \"driver\" else 0.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254bf09-7e03-49c2-a711-6ddffb319a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_idx = np.random.choice(len(seqs), size=200, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e8b81-cda3-464b-ac06-706b3bb1ecc1",
   "metadata": {},
   "source": [
    "### Define GP Model and Kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06438e9-5fae-4c67-8521-8afa67f13a5c",
   "metadata": {},
   "source": [
    "## IMQH-GP and LSE setup \n",
    "Let $\\mathcal{X} = \\{x_1, x_2, \\dots, x_N\\}$ be a set of mutation sequences. At each iteration $t$, the labeled set is $\\mathcal{I}_t \\subset \\mathcal{X}$ and the unlabeled set is $\\mathcal{U}_t = \\mathcal{X} - \\mathcal{I}_t$.\n",
    "\n",
    "We model the latent function $f$ over sequences using a Gaussian Process prior:\n",
    "$$ f(x) \\sim \\mathcal{GP}(0, k(x, x'))$$\n",
    "where $k(x, x')$ is the IMQ-Hamming kernel:\n",
    "$$\n",
    "k(x, x') = \\frac{(1 + s)^\\beta}{(s + d_H(x, x'))^\\beta}\n",
    "$$\n",
    "with scale parameter $s > 0$, shape parameter $\\beta > 0$, and $d_H$ is the Hamming distance over k-mers.\n",
    "\n",
    "## Gaussian Process Posterior Predictions\n",
    "\n",
    "Given the current labeled data $\\mathcal{I}_t$, for each $x \\in \\mathcal{U}_t$, the GP provides:\n",
    "1) Predictive mean: $\\mu_t(x)$\n",
    "2) Predictive variance: $\\sigma^2_t(x)$\n",
    "\n",
    "## Confidence Invervals\n",
    "We compute a high-probability confidence interval (CI) for $f(x)$:\n",
    "$$\n",
    "\\mathrm{CI}_t(x) = \\left[ \\mu_t(x) - \\beta_t^{1/2} \\sigma_t(x), \\, \\mu_t(x) + \\beta_t^{1/2} \\sigma_t(x) \\right]\n",
    "$$ where\n",
    "$$\n",
    "\\beta_t = 2 \\log\\left( \\frac{\\pi^2 (t+1)^2}{6 \\delta} \\right)\n",
    "$$\n",
    "and $\\delta \\in (0,1)$ is a confidence parameter (typically $\\delta = 0.01$).\n",
    "\n",
    "## Threshold Classification\n",
    "A threshold $h_t$ is used to decide whether $x$ is classified as a \\emph{driver} or \\emph{passenger}. This can be:\n",
    "1) Explicit $h_t = h$, e.g., $h = 0.5$\n",
    "2) Implicit $h_t = \\omega \\cdot \\max_{x \\in \\mathcal{U}_t} \\mu_t(x)$, where $\\omega \\in (0, 1)$\n",
    "Each point $x \\in \\mathcal{U}_t$ is classified based on its confidence interval:\n",
    "\n",
    "1) **Driver (high)** & $\\quad \\text{if} \\quad \\mu_t(x) - \\beta_t^{1/2} \\sigma_t(x) > h_t - \\epsilon$ \n",
    "2) **Passenger (low)** & $\\quad \\text{if} \\quad \\mu_t(x) + \\beta_t^{1/2} \\sigma_t(x) < h_t + \\epsilon$\n",
    "\n",
    "All other points remain unlabeled.\n",
    "\n",
    "## Acquisition Rule\n",
    "From the remaining unlabeled points $\\mathcal{U}_t$, the next query $x^\\ast$ is chosen according to a rule:\n",
    "\n",
    "1) **Ambiguity:**\n",
    "\n",
    "$$x^\\ast = \\arg\\max_{x \\in \\mathcal{U}_t} \\min\\left( \\mu_t(x) + \\beta_t^{1/2} \\sigma_t(x) - h_t,\\; h_t - (\\mu_t(x) - \\beta_t^{1/2} \\sigma_t(x)) \\right)$$\n",
    "\n",
    "2) **Variance**\n",
    "\n",
    "$$x^\\ast = \\arg\\max_{x \\in \\mathcal{U}_t} \\sigma_t(x)$$\n",
    "\n",
    "The selected point is queried (labeled), added to $\\mathcal{I}_t$, and the GP is updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acfc5f-eb44-4cc2-b451-420d9a22b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import imq_gp \n",
    "\n",
    "from imq_gp import ZeroMeanIMQHGP, IMQHGP_Params\n",
    "\n",
    "gp_model = ZeroMeanIMQHGP([seqs[i] for i in init_idx], jnp.array(labels[init_idx]))\n",
    "\n",
    "# Set hyperparameters\n",
    "params = IMQHGP_Params(\n",
    "    raw_amplitude=jnp.array(1.0),\n",
    "    raw_noise=jnp.array(1e-4),\n",
    "    scale=1.0,\n",
    "    beta=0.5,\n",
    "    lag=1,\n",
    "    alphabet_name=\"prot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1979a-cfb4-4958-a4a5-9ef9dfcf9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute full kernel matrices\n",
    "import jax.numpy as jnp\n",
    "from imq_gp import imq_hamming_kernel\n",
    "\n",
    "X_pool = seqs\n",
    "X_train = [seqs[i] for i in init_idx]\n",
    "X_test = [seqs[i] for i in range(len(seqs)) if i not in init_idx]\n",
    "\n",
    "# This is the full train and test indices\n",
    "train_idx = init_idx\n",
    "test_idx = [i for i in range(len(seqs)) if i not in train_idx]\n",
    "\n",
    "K_train_train = imq_hamming_kernel(X_train, X_train, alphabet_name='prot', scale=1.0, beta=0.5, lag=1)\n",
    "K_test_train = imq_hamming_kernel(X_test, X_train, alphabet_name='prot', scale=1.0, beta=0.5, lag=1)\n",
    "K_test_test = imq_hamming_kernel(X_test, X_test, alphabet_name='prot', scale=1.0, beta=0.5, lag=1)\n",
    "\n",
    "# Store in the model\n",
    "gp_model._K_train_train = jnp.asarray(K_train_train)\n",
    "gp_model._K_test_train = jnp.asarray(K_test_train)\n",
    "gp_model._K_test_test = jnp.asarray(K_test_test)\n",
    "gp_model._X_test = X_test\n",
    "gp_model._test_idx = test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cd8dc-0d67-420a-b014-1ff8046ee467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import imq_gp \n",
    "from lse import LSE\n",
    "\n",
    "try:\n",
    "    del lse\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "#Run LSE\n",
    "lse = LSE(\n",
    "    model=gp_model,\n",
    "    params=params,\n",
    "    X_pool=seqs,\n",
    "    y_pool=labels,\n",
    "    init_indices=init_idx,\n",
    "    omega=0.40,       \n",
    "    epsilon=0.05,\n",
    "    rule=\"amb\",      \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run seed IMQH-GP-LSE algorithm\n",
    "lse.run(max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0f24e-62f1-4114-9bf2-534251c0c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mu_all, _ = gp_model.predict_f(params, seqs, full_covar=False)\n",
    "plt.hist(np.array(mu_all), bins=20)\n",
    "plt.axvline(x=lse._threshold(mu_all), color='red', linestyle='--', label='Threshold')\n",
    "plt.title(\"Posterior mean (μ) distribution over all points\")\n",
    "plt.xlabel(\"μ\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe09cb-56b6-46c4-9bb5-98298b5a6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df[\"Type\"].apply(lambda x: 1 if x.lower() == \"driver\" else 0).values\n",
    "mutations = df[\"Mutation\"].values\n",
    "\n",
    "# Queried indices and model predictions\n",
    "queried_indices = lse.vt\n",
    "pred_labels = [1 if i in lse.ht else 0 for i in queried_indices]\n",
    "true_labels_queried = [true_labels[i] for i in queried_indices]\n",
    "\n",
    "# Accuracy tracking\n",
    "correct = [int(p == t) for p, t in zip(pred_labels, true_labels_queried)]\n",
    "correct_mutations = [mutations[i] for i, is_correct in zip(queried_indices, correct) if is_correct]\n",
    "\n",
    "# Print results\n",
    "print(\"Queried mutation predictions (index, mutation, true, predicted, correct?):\")\n",
    "for idx, pred, true in zip(queried_indices, pred_labels, true_labels_queried):\n",
    "    tag = \"✓\" if pred == true else \"✗\"\n",
    "    print(f\"  idx={idx:2d}, {mutations[idx]:>8}, true={true}, pred={pred}  {tag}\")\n",
    "\n",
    "# Summary\n",
    "num_correct = sum(correct)\n",
    "print(f\"\\nCorrect predictions: {num_correct} / {len(queried_indices)}\")\n",
    "print(f\"Accuracy on queried points: {num_correct / len(queried_indices):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bff83-f33a-4f98-8cb2-2d7b3ccaabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## maybe use a sigmoid link or logistic link function for f(x) \\in [0,1] instead of CI being negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sequence_kernels)",
   "language": "python",
   "name": "sequence_kernels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
